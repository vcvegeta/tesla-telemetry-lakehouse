# Tesla Telemetry Lakehouse - Production Docker Compose
# GitHub: https://github.com/vcvegeta/tesla-telemetry-lakehouse
# Docker Hub: hub.docker.com/u/viraat

name: tesla-telemetry

x-airflow-common: &airflow-common
  image: apache/airflow:2.9.3
  environment: &airflow-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    AIRFLOW__CORE__FERNET_KEY: ""
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - airflow_logs:/opt/airflow/logs
    - /var/run/docker.sock:/var/run/docker.sock
  user: "0:0"
  depends_on:
    - postgres

services:
  # PostgreSQL - Stores Airflow metadata and Gold layer data
  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

  # MinIO - S3-compatible object storage for lakehouse
  minio:
    image: minio/minio:RELEASE.2024-12-18T13-15-44Z
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio12345
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    restart: unless-stopped

  # MinIO bucket initialization
  minio-init:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      sleep 5;
      mc alias set myminio http://minio:9000 minio minio12345;
      mc mb myminio/lakehouse --ignore-existing;
      echo 'âœ… MinIO lakehouse bucket created';
      "
    restart: "no"

  # Zookeeper - Required for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: unless-stopped

  # Kafka - Streaming data ingestion
  kafka:
    image: confluentinc/cp-kafka:7.6.1
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    restart: unless-stopped

  # Data Ingestor - Generates Tesla telemetry data
  ingestor:
    image: viraat/tesla-telemetry-ingestor:latest
    depends_on:
      - kafka
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: telemetry_raw
    restart: unless-stopped

  # Spark Master (Streaming Cluster)
  spark-master:
    image: viraat/tesla-telemetry-spark:latest
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      SPARK_MASTER_HOST: spark-master
    restart: unless-stopped

  # Spark Worker 1 (Streaming Cluster)
  spark-worker-1:
    image: viraat/tesla-telemetry-spark:latest
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
    ports:
      - "8081:8081"
    restart: unless-stopped

  # Spark Worker 2 (Streaming Cluster)
  spark-worker-2:
    image: viraat/tesla-telemetry-spark:latest
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
    ports:
      - "8082:8081"
    restart: unless-stopped

  # Spark Master (Batch Cluster)
  spark-master-batch:
    image: viraat/tesla-telemetry-spark:latest
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8083:8080"
      - "7078:7077"
    environment:
      SPARK_MASTER_HOST: spark-master-batch
    restart: unless-stopped

  # Spark Worker (Batch Cluster)
  spark-worker-batch:
    image: viraat/tesla-telemetry-spark:latest
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master-batch:7077
    depends_on:
      - spark-master-batch
    environment:
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
    ports:
      - "8084:8081"
    restart: unless-stopped

  # Streaming Job: Kafka to Bronze Layer
  streaming-kafka-to-bronze:
    image: viraat/tesla-telemetry-spark:latest
    depends_on:
      - spark-master
      - kafka
      - minio
    user: "0:0"
    environment:
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: minio12345
    command: >
      /opt/spark/bin/spark-submit
      --master spark://spark-master:7077
      --deploy-mode client
      --driver-memory 1g
      --executor-memory 1g
      --executor-cores 2
      --total-executor-cores 2
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.apache.hadoop:hadoop-aws:3.3.4
      /opt/spark/work-dir/spark/streaming_jobs/kafka_to_minio_bronze.py
    volumes:
      - spark_ivy_cache:/home/spark/.ivy2
    restart: always

  # Streaming Job: Bronze to Silver Layer
  streaming-bronze-to-silver:
    image: viraat/tesla-telemetry-spark:latest
    depends_on:
      - streaming-kafka-to-bronze
    user: "0:0"
    environment:
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: minio12345
    command: >
      /opt/spark/bin/spark-submit
      --master spark://spark-master:7077
      --deploy-mode client
      --driver-memory 1g
      --executor-memory 1g
      --executor-cores 2
      --total-executor-cores 2
      --packages org.apache.hadoop:hadoop-aws:3.3.4
      /opt/spark/work-dir/spark/streaming_jobs/bronze_to_silver.py
    volumes:
      - spark_ivy_cache:/home/spark/.ivy2
    restart: always

  # Airflow Scheduler - Orchestrates batch jobs
  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    restart: unless-stopped

  # Airflow Webserver - UI for monitoring
  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8089:8080"
    restart: unless-stopped

  # Airflow Initialization - Creates admin user
  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db migrate &&
        airflow users create \
          --username admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com \
          --password admin || true
    restart: "no"

  # Apache Superset - Data visualization and dashboards
  superset:
    image: viraat/tesla-telemetry-superset:latest
    ports:
      - "8088:8088"
    environment:
      SUPERSET_SECRET_KEY: "change_me_please"
    depends_on:
      - postgres
    volumes:
      - superset_data:/app/superset_home
    restart: unless-stopped

volumes:
  postgres_data:
  minio_data:
  airflow_logs:
  superset_data:
  spark_ivy_cache:
